{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       term               dma_name    month  score  rank  \\\n",
      "0              Aaron Gordon  Abilene-Sweetwater TX  2024-01    NaN  10.0   \n",
      "1              Aaron Gordon  Abilene-Sweetwater TX  2024-02    NaN  10.0   \n",
      "2              Aaron Gordon  Abilene-Sweetwater TX  2024-03    NaN  10.0   \n",
      "3              Aaron Gordon  Abilene-Sweetwater TX  2024-04    NaN  10.0   \n",
      "4              Aaron Gordon  Abilene-Sweetwater TX  2024-05    NaN  10.0   \n",
      "...                     ...                    ...      ...    ...   ...   \n",
      "50669  When is Father's Day          Zanesville OH  2024-01    NaN  14.0   \n",
      "50670  When is Father's Day          Zanesville OH  2024-02    NaN  14.0   \n",
      "50671  When is Father's Day          Zanesville OH  2024-03    NaN  14.0   \n",
      "50672  When is Father's Day          Zanesville OH  2024-04    NaN  14.0   \n",
      "50673  When is Father's Day          Zanesville OH  2024-05    NaN  14.0   \n",
      "\n",
      "      refresh_date  dma_id  \n",
      "0       2024-05-13     662  \n",
      "1       2024-05-13     662  \n",
      "2       2024-05-13     662  \n",
      "3       2024-05-13     662  \n",
      "4       2024-05-13     662  \n",
      "...            ...     ...  \n",
      "50669   2024-05-13     596  \n",
      "50670   2024-05-13     596  \n",
      "50671   2024-05-13     596  \n",
      "50672   2024-05-13     596  \n",
      "50673   2024-05-13     596  \n",
      "\n",
      "[50674 rows x 7 columns]\n",
      "             week  score  rank refresh_date           dma_name  dma_id  \\\n",
      "58839  2024-01-07   10.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58840  2024-01-21    6.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58841  2024-02-04    7.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58842  2024-02-11    7.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58843  2024-02-18    4.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58844  2024-02-25    7.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58845  2024-03-17    7.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58846  2024-03-24    7.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58847  2024-03-31    5.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58848  2024-04-28   15.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "58849  2024-05-05   17.0    24   2024-05-11  Salt Lake City UT     770   \n",
      "113395 2024-01-07   10.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113396 2024-01-21    7.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113397 2024-02-04    7.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113398 2024-02-11    7.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113399 2024-02-25    7.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113400 2024-03-17    9.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113401 2024-03-24    7.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113402 2024-03-31    6.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "113403 2024-04-28   14.0    24   2024-05-13  Salt Lake City UT     770   \n",
      "\n",
      "           term  \n",
      "58839   Celtics  \n",
      "58840   Celtics  \n",
      "58841   Celtics  \n",
      "58842   Celtics  \n",
      "58843   Celtics  \n",
      "58844   Celtics  \n",
      "58845   Celtics  \n",
      "58846   Celtics  \n",
      "58847   Celtics  \n",
      "58848   Celtics  \n",
      "58849   Celtics  \n",
      "113395  Celtics  \n",
      "113396  Celtics  \n",
      "113397  Celtics  \n",
      "113398  Celtics  \n",
      "113399  Celtics  \n",
      "113400  Celtics  \n",
      "113401  Celtics  \n",
      "113402  Celtics  \n",
      "113403  Celtics  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>dma_name</th>\n",
       "      <th>month</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "      <th>refresh_date</th>\n",
       "      <th>dma_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9344</th>\n",
       "      <td>Celtics</td>\n",
       "      <td>Salt Lake City UT</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>Celtics</td>\n",
       "      <td>Salt Lake City UT</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>Celtics</td>\n",
       "      <td>Salt Lake City UT</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>Celtics</td>\n",
       "      <td>Salt Lake City UT</td>\n",
       "      <td>2024-04</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9348</th>\n",
       "      <td>Celtics</td>\n",
       "      <td>Salt Lake City UT</td>\n",
       "      <td>2024-05</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2024-05-11</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term           dma_name    month      score  rank refresh_date  \\\n",
       "9344  Celtics  Salt Lake City UT  2024-01   8.250000  24.0   2024-05-13   \n",
       "9345  Celtics  Salt Lake City UT  2024-02   6.571429  24.0   2024-05-13   \n",
       "9346  Celtics  Salt Lake City UT  2024-03   6.833333  24.0   2024-05-13   \n",
       "9347  Celtics  Salt Lake City UT  2024-04  14.500000  24.0   2024-05-13   \n",
       "9348  Celtics  Salt Lake City UT  2024-05  17.000000  24.0   2024-05-11   \n",
       "\n",
       "      dma_id  \n",
       "9344     770  \n",
       "9345     770  \n",
       "9346     770  \n",
       "9347     770  \n",
       "9348     770  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Google-query data files\n",
    "google_query_path = \"data/Google_Bigquery_Top_Search_Jan_Jun_2024.csv\"\n",
    "google_query_data = pd.read_csv(google_query_path)\n",
    "\n",
    "# Read the CSV into a Pandas DataFrame\n",
    "google_queryDF = pd.DataFrame(google_query_data)\n",
    "\n",
    "# Convert 'week' column to datetime format\n",
    "google_queryDF['week'] = pd.to_datetime(google_queryDF['week'])\n",
    "\n",
    "# Group by month, term. and DMA and aggregate the data\n",
    "monthly_data = google_queryDF.groupby(['term', 'dma_name', google_queryDF['week'].dt.to_period('M')]).agg({\n",
    "    'score': 'mean',\n",
    "    'rank': 'mean',\n",
    "    'refresh_date': 'max',  # Get the latest refresh_date in the month\n",
    "    'dma_id': 'first',       # Get the first dma_id in the month\n",
    "  }).reset_index()\n",
    "\n",
    "monthly_data.rename(columns={'week': 'month'}, inplace=True)\n",
    "\n",
    "# Display the monthly data\n",
    "print(monthly_data)\n",
    "monthly_data.tail()\n",
    "\n",
    "#Print out a sample case (searches for \"Celtics\" in SLC DMA) of aggregating search terms by month \n",
    "filtered_df = google_queryDF[(google_queryDF['term'] == 'Celtics') & (google_queryDF['dma_name'] == 'Salt Lake City UT')]\n",
    "print(filtered_df)\n",
    "\n",
    "month_filtered_df = monthly_data[(monthly_data['term'] == 'Celtics') & (monthly_data['dma_name'] == 'Salt Lake City UT')]\n",
    "month_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Filtered DataFrame:\n",
      "            week  score  rank refresh_date               dma_name  dma_id  \\\n",
      "38148 2024-01-28    NaN    24   2024-05-15     Portland-Auburn ME     500   \n",
      "38149 2024-02-04    NaN    24   2024-05-15     Portland-Auburn ME     500   \n",
      "38150 2024-03-03    NaN    24   2024-05-15     Portland-Auburn ME     500   \n",
      "38151 2024-03-10    NaN    24   2024-05-15     Portland-Auburn ME     500   \n",
      "38152 2024-03-17    NaN    24   2024-05-15     Portland-Auburn ME     500   \n",
      "...          ...    ...   ...          ...                    ...     ...   \n",
      "86377 2024-02-11    NaN     3   2024-05-11  Abilene-Sweetwater TX     662   \n",
      "86378 2024-03-24    NaN     3   2024-05-11  Abilene-Sweetwater TX     662   \n",
      "86379 2024-03-31    NaN     3   2024-05-11  Abilene-Sweetwater TX     662   \n",
      "86380 2024-04-07    NaN     3   2024-05-11  Abilene-Sweetwater TX     662   \n",
      "86381 2024-05-05   19.0     3   2024-05-11  Abilene-Sweetwater TX     662   \n",
      "\n",
      "                          term                    Team  \n",
      "38148              Mike Conley  Minnesota Timberwolves  \n",
      "38149              Mike Conley  Minnesota Timberwolves  \n",
      "38150              Mike Conley  Minnesota Timberwolves  \n",
      "38151              Mike Conley  Minnesota Timberwolves  \n",
      "38152              Mike Conley  Minnesota Timberwolves  \n",
      "...                        ...                     ...  \n",
      "86377  Nuggets vs Timberwolves  Minnesota Timberwolves  \n",
      "86378  Nuggets vs Timberwolves  Minnesota Timberwolves  \n",
      "86379  Nuggets vs Timberwolves  Minnesota Timberwolves  \n",
      "86380  Nuggets vs Timberwolves  Minnesota Timberwolves  \n",
      "86381  Nuggets vs Timberwolves  Minnesota Timberwolves  \n",
      "\n",
      "[3925 rows x 8 columns]\n",
      "week\n",
      "2024-02-25    1319\n",
      "2024-03-31    1312\n",
      "2024-04-21    1294\n",
      "2024-02-18    1294\n",
      "2024-04-28    1284\n",
      "2024-04-14    1284\n",
      "2024-03-03    1279\n",
      "2024-03-17    1271\n",
      "2024-01-21    1268\n",
      "2024-03-24    1265\n",
      "2024-02-11    1265\n",
      "2024-04-07    1264\n",
      "2024-01-07    1256\n",
      "2024-05-05    1246\n",
      "2024-03-10    1240\n",
      "2024-01-14    1230\n",
      "2024-01-28    1219\n",
      "2024-02-04    1215\n",
      "2024-05-12     757\n",
      "Name: count, dtype: int64\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to associate Teams with Terms\n",
    "team_terms = {\n",
    "    'Boston Celtics': ['Celtics'],\n",
    "    'Dallas Mavericks': ['Mavericks'],\n",
    "    'Denver Nuggets': ['Aaron Gordon', 'Nikola Jokic', 'Nuggets vs Timberwolves'],\n",
    "    'Minnesota Timberwolves': ['Mike Conley', 'Nuggets vs Timberwolves', 'Naz Reid'],\n",
    "    'New York Knicks': ['Knicks', 'Donte DiVincenzo']\n",
    "}\n",
    "\n",
    "# Filter seach dataset of 'Terms' based on the 'Teams' using list comprehension:\n",
    "# all_terms = ['Term1', 'Term2', 'Term3', 'Term4', 'Term5', 'Term6']\n",
    "\n",
    "# Create an empty list to store the filtered DataFrames with the 'Team' value\n",
    "filtered_dfs = []\n",
    "\n",
    "# # Iterate through each team in team_terms and filter the DataFrame based on each team's terms\n",
    "for team, terms in team_terms.items():\n",
    "    filtered_df = google_queryDF[google_queryDF['term'].apply(lambda x: x in terms)].copy()\n",
    "    filtered_df['Team'] = team  # Add the 'Team' value to the filtered DataFrame\n",
    "    filtered_dfs.append(filtered_df)\n",
    "\n",
    "# Concatenate all filtered DataFrames into a single DataFrame\n",
    "filtered_combined_df = pd.concat(filtered_dfs)\n",
    "\n",
    "# Access and print the combined filtered DataFrame\n",
    "print(\"Combined Filtered DataFrame:\")\n",
    "print(filtered_combined_df[filtered_combined_df['Team']==\"Minnesota Timberwolves\"])\n",
    "\n",
    "print(filtered_combined_df[\"week\"].value_counts())\n",
    "print(filtered_combined_df[\"week\"].nunique())\n",
    "\n",
    "#This approach provides a flexible and efficient way to associate terms with teams and filter a large dataset based on these associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the file containing the search terms filtered by NBA teams\n",
    "import csv\n",
    "\n",
    "# Define the output file path\n",
    "output_file = \"data/terms_by_teams.csv\"\n",
    "\n",
    "# Define the header for the CSV file\n",
    "header = [\"Team\", \"Week\", \"Term\",\"Rank\",\"dma_name\",\"dma_id\",\"score\",\"refresh_date\"]\n",
    "\n",
    "# Open the output file and write the header\n",
    "with open(output_file, \"w\", newline='') as datafile:\n",
    "    writer = csv.writer(datafile)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # Iterate through the rows of the DataFrame and write each row to the CSV file\n",
    "    for index, row in filtered_combined_df.iterrows():\n",
    "        Team = row[\"Team\"]\n",
    "        Week = row[\"week\"]\n",
    "        term = row[\"term\"]\n",
    "        rank = row[\"rank\"]\n",
    "        dma_name = row[\"dma_name\"]\n",
    "        dma_id = row[\"dma_id\"]\n",
    "        score = row[\"score\"]\n",
    "        refresh_date = row[\"refresh_date\"]\n",
    "        data_row = [Team, Week, term, score, rank, refresh_date,dma_name,dma_id]\n",
    "        writer.writerow(data_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/teams_playoffs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m NBA_2024_records \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/teams_playoffs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m NBA_query_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(NBA_2024_searches)\n\u001b[1;32m----> 7\u001b[0m NBA_records_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNBA_2024_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Read the CSV into a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m     10\u001b[0m NBA_queryDF \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(NBA_query_data)\n",
      "File \u001b[1;32mc:\\Users\\johns\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johns\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\johns\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johns\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\johns\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/teams_playoffs.csv'"
     ]
    }
   ],
   "source": [
    "# Study data files\n",
    "NBA_2024_searches = \"data/terms_by_teams.csv\"\n",
    "NBA_2024_records = \"../ucb-data-analytics-project1-group5/data/teams_playoffs.csv\"\n",
    "\n",
    "\n",
    "NBA_query_data = pd.read_csv(NBA_2024_searches)\n",
    "NBA_records_data = pd.read_csv(NBA_2024_records)\n",
    "\n",
    "# Read the CSV into a Pandas DataFrame\n",
    "NBA_queryDF = pd.DataFrame(NBA_query_data)\n",
    "NBA_recordsDF = pd.DataFrame(NBA_records_data)\n",
    "\n",
    "# Display the data table for preview\n",
    "print(NBA_queryDF)\n",
    "#print(NBA_recordsDF)\n",
    "\n",
    "#Merge the two DataFrames NBA_queryDF and NBA_recordsDF on the fields \"Team\" and \"Week\"\n",
    "NBA_analysis_df = pd.merge(NBA_queryDF, NBA_recordsDF, on=['Team', 'Week'])\n",
    "\n",
    "# Display the data table for preview\n",
    "NBA_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient between 'Round' and 'Rank': 0.127711418878646\n",
      "Pearson correlation coefficient between 'Cum_win_pct' and 'Rank': -0.3881474294044364\n"
     ]
    }
   ],
   "source": [
    "correlation = NBA_analysis_df['Round'].corr(NBA_analysis_df['Rank'])\n",
    "print(f\"Pearson correlation coefficient between 'Round' and 'Rank': {correlation}\")\n",
    "\n",
    "correlation = NBA_analysis_df['Cum_win_pct'].corr(NBA_analysis_df['Rank'])\n",
    "print(f\"Pearson correlation coefficient between 'Cum_win_pct' and 'Rank': {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team                 0\n",
      "Week                 0\n",
      "Term                 0\n",
      "Rank                 0\n",
      "dma_name             0\n",
      "dma_id               0\n",
      "score                0\n",
      "refresh_date         0\n",
      "PW_win_pct        4581\n",
      "Weekly_win_pct    4581\n",
      "Cum_win_pct       4581\n",
      "Round                0\n",
      "dtype: int64\n",
      "Mean Squared Error: 298.100792110836\n",
      "Intercept: 5.464241709402251\n",
      "Coefficient: 23.18737102104605\n",
      "Predicted search rank for playoff round 4 (NBA championship): 98.21372579358645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_32764\\1124840885.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  NBA_analysis_df['Round'].fillna(0, inplace=True)\n",
      "c:\\Users\\johns\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Handle missing values in the dataset:\n",
    "# Check for missing values in the dataset\n",
    "print(NBA_analysis_df.isnull().sum())\n",
    "\n",
    "# Handle missing values by dropping rows with NaN values\n",
    "NBA_analysis_df['Rank'].fillna(0, inplace=True)\n",
    "NBA_analysis_df['Round'].fillna(0, inplace=True)\n",
    "\n",
    "#Define the independent variable 'Rank' and the dependent variable 'Cum_win_pct':\n",
    "X = NBA_analysis_df[['Round']]  # Independent variable (Rank)\n",
    "y = NBA_analysis_df['Rank']  # Dependent variable (Cumulative Win Percentage)\n",
    "\n",
    "#Split the data into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Fit a linear regression model to the training data:\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions using the model:\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Evaluate the model performance:\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "#Interpret the model coefficients:\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficient:\", model.coef_[0])\n",
    "\n",
    "#Predict how changes in search rankings may impact what round a playoff team reaches:\n",
    "# Example prediction for a specific team ranking\n",
    "playoff_round = 4\n",
    "predicted_rank = model.predict([[playoff_round]])\n",
    "\n",
    "print(f\"Predicted search rank for playoff round {playoff_round} (NBA championship): {predicted_rank[0]}\")\n",
    "#By following these steps and running the provided Python code, you can conduct regression analysis to model the relationship between 'Rank' and 'Cum_win_pct' in your DataFrame and predict how changes in team rankings may impact their cumulative win percentages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
